\section{Conclusion}
\label{conclusion}
In this paper, to predict the execution time of Apache Spark job interfered with other jobs, we develop an interference model. This model combines the execution information and resource consumption profile for each stage of Apache Spark jobs to calculate the slowdown ratio resulting from the interference, and then predict the execution time when interfered with other jobs. The model is evaluated using four real-life applications (e.g., Page rank , K-means, Logistic regression, Word count) on a 6 node cluster while running up to four jobs concurrently. Experimental results demonstrate that our model can achieve high prediction accuracy. We strongly believe that the presented model can be leveraged to design efficient job schedulers and resource allocation algorithms for Apache Spark platform, thereby improving the system utilization significantly. 

