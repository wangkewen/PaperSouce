\section{Introduction}
\label{intro}
Among different cloud computing platforms, Apache Spark~\cite{spark} is one of the recently popularized open-source platforms that is currently used by over 500 organizations, including companies such as Amazon, eBay and Baidu\footnote{http://spark.apache.org/faq.html}. Apache Spark leverages the concept of resilient distributed datasets (RDDs)~\cite{rdd} and in-memory computation to enable fast processing of large volume of data, making it suitable for large-scale data analytic applications. However, while performance prediction in such systems is important to optimize resource allocation~\cite{khan2015hadoop}~\cite{cheng2015resource}~\cite{delimitrou2014quasar}, it is nontrivial for Apache Spark jobs for several reasons as follows. First, the execution time of a particular job on Apache Spark platform can vary significantly depending on the input data type and size, design and implementation of the algorithm, and computing capability (e.g., number of nodes, CPU speed, memory size), making it difficult to predict job performance. Second and finally, with advancement in hardware technology, virtualization technique is increasingly being used to share resources among applications~\cite{hybridmr}. However, while virtualization isolates multiple applications running on separate virtual machines, the interference among these applications still affects the execution performance. Due to the aforementioned factors, modeling performance of multiple Apache Spark jobs running in a virtualized environment concurrently is extremely challenging. While our own prior effort looked into the problem of performance prediction for a single job running on Apache Spark platform~\cite{wangperformance}, that approach does not address the challenge of performance modeling for multiple jobs running in parallel on the same cluster.
\noindent
To address this void, in this paper, we focus on modeling interference among multiple Apache Spark jobs, and predict the execution time of a job when interfered with other jobs.
In contrast to hard to interpret machine learning approaches that are often used to predict system performance leveraging past system execution data, we apply analytical approach that can provide a better understanding regarding the observed behavior (e.g., execution slowdown), exposing the underlying interactions among multiple jobs~\cite{ousterhout2015making}~\cite{noorshams2014automated}~\cite{zhu2012performance} ~\cite{lai2014io}. Specifically, we use jobs (implemented by us) to predict the slowdown ratio while running multiple jobs concurrently, and use the slowdown ratio to predict the execution time. As Apache spark jobs follow a multi-stage execution model (more details are discussed in Section~\ref{overview}) and different stages have different characteristics (e.g., I/O intensive vs. CPU intensive), our framework develops interference models for each stage, and predict execution time for each stage separately. 
\noindent
We evaluated our framework with four real-world applications, namely, Page Rank, K-means clustering algorithm, Logistic regression, and Word Count application. We vary the number of concurrent jobs up to 4 and predicted execution time for individual stages. While the prediction accuracy for individual stages vary, it ranges between 86\% to 99\% when the number of concurrent jobs are four and all start simultaneously, and ranges between 71\% to 99\% when the number of concurrent jobs are four and start at different times. 
\noindent
The rest of the paper is organized as follows. Section~\ref{related} describes prior research that is related to our work. Section~\ref{overview} explains the models that are used to predict job performance. Section~\ref{evaluation} presents the experimental results. Limitations of our current work is discussed in Section~\ref{discussion}. Finally, Section~\ref{conclusion} concludes the paper.


