\section{Overview}
\label{overview}

\noindent
In our model, each Apache Spark job consists of multiple execution stages where each stage implements distinct operations of an application program and are executed sequentially. Moreover, to facilitate parallel processing, input data set is partitioned into multiple sets and are distributed over multiple worker nodes. Within each worker node, batches of tasks are launched to process the corresponding partition of the input data. The number of tasks within each node is determined based on the size of the input data and configuration settings of the program. 
\nop{
\noindent
To illustrate the main idea behind Apache Spark job execution, let us consider the Apache Spark PageRank job running on two worker nodes: A and B, where Node A has 8 CPU cores and Node B has 12 CPU cores as shown in Figure~\ref{flow}. This PageRank job will have 13 stages if the iteration number is set to 10, where stage 1 and stage 2 executes the distinct() operation. In the iteration part from stage 3 to stage 12, the operation reduceByKey() is executed. The final stage performs the saveAsTextFile() operation. As shown in Figure~\ref{flow}, each box in the Figure represents one stage, and each line in the box represents one task. Different colors are used to differentiate tasks running on different worker nodes. 
}

\noindent
For example, if the input data size of the PageRank job is 2.5 GB, the total number of input blocks will be 40 for a default block size of 64 MB. As the number of tasks is the same as the input block number and the number of tasks in each stage is same within one Spark job, there will be 40 tasks in each stage. However, different CPU core may complete different number of tasks due to the difference in computing ability and uncertainty during the program execution. \nop{
\begin{figure}[!t]
\centering
\includegraphics[width=3.0in]{figures/flow.png}
\caption{Prediction Accuracy for WordCount}
\label{flow}
\end{figure}
}
\begin{figure}[!t]
\centering
\includegraphics[width=3.3in]{figures/flow1.pdf}
\caption{Performance Prediction for Interfered Jobs}
\label{flow}
\end{figure}

\noindent
Given the above multistage execution model, the main idea behind our work is as follows (Figure~\ref{flow}). First, for a given Apache Spark job, we predict the execution time for each stage leveraging the performance model developed based on performance of sample job with smaller input data set. Please note that this model is presented in our prior work~\cite{wangperformance}, and assumes that there are no interference in the system from other jobs. Next, we estimate the slowdown ratio for a given number of jobs running concurrently by executing our simulation job, which is implemented by us (more details in Section~\ref{evaluation}) and is different than any of the four jobs that we used for evaluation. However, as the slowdown ratio due to interference among simulated jobs can be different compared to actual jobs, for a given job, we adjust the expected slowdown ratio by taking into account the actual job parameters such as input data size and disk I/O characteristics. Once we estimate the expected slowdown ratio, we estimate the execution time considering the interference. For completeness, we first briefly present the model that is used to predict execution time assuming no interference from our earlier work~\cite{wangperformance}, and then present the model for predicting the slowdown ratio due to interference, which is the contribution of this work that allows us to predict execution time in the presence of interference among multiple jobs. 


\subsection{Model for Estimating Execution Time}
\label{oldmodel}
As an Apache Spark job is executed in multiple stages where each stage contains multiple tasks, we use the following notation to represent an Apache Spark job:
\begin{IEEEeqnarray}{rCl}
\label{jobperform}
Job &{} ={}& \{Stage_i \mid 0 \leq i \leq M \} \\
Stage_i &{} ={}& \{Task_{i,j} \mid 0 \leq j \leq N \} 
\end{IEEEeqnarray}
Here $M$ is the number of stages in a job and $N$ is the number of tasks in a stage. 
\noindent
Next, as different stages within a job are executed sequentially, we represent the execution time of a job as the sum of the execution time of each stage plus the job startup time and the job cleanup time as follows:
\begin{IEEEeqnarray}{rCl}
\label{jobtime}
JobTime = Startup + \sum_{s=1}^{M} StageTime_{s} + Cleanup
\end{IEEEeqnarray}
Next, within each stage, as one CPU core executes one task at a time, in a cluster with $H$ worker nodes, the number of tasks $P$ that can run in parallel can be calculated as follows:
\begin{IEEEeqnarray}{rCl}
\label{paralltask}
P=\sum_{h=1}^H CoreNum_{h}
\end{IEEEeqnarray}
Here, $CoreNum_{h}$ is the number of CPU cores of working node $h$ and $H$ is the number of working nodes in the cluster. Hence, within an execution stage, tasks in each stage are executed in batches where each batch consists of $P$ tasks running in parallel. However, due to the differences in computing capabilities among different worker nodes in a cluster and inherent uncertainty in program execution, the execution time of different tasks may vary significantly. Therefore, the time spent in a particular stage can be calculated as the maximum of the sum of all the sequential tasks' time within a stage plus the stage startup time and the stage cleanup time as follows:
\begin{IEEEeqnarray}{rCl}
\label{stagetime}
StageTime&{} ={}& Startup + \max_{c=1}^{P} \sum_{i=1}^{K_c} TaskTime_{c,i} \nonumber \\
&&+Cleanup
\end{IEEEeqnarray}
Here $P$ is the number of total CPU cores, and $K_c$ is the number of sequential tasks executed on CPU core $c$.
Finally, as different tasks in a stage follow the same execution pattern, the execution time of a task can be computed as follows:
\begin{IEEEeqnarray}{rCl}
\label{tasktime}
TaskTime&{} ={}& DeserializationTime + RunTime \nonumber \\
&&+ SerializationTime
\end{IEEEeqnarray}
Here $DeserializationTime$ is the time taken to deserialize the input data, $SerializationTime$ is the time taken to serialize the result, and $RunTime$ is the actual time spent performing operations on data such as data mapping, filtering, calculating, and analyzing. 
Based on the above model, to predict job performance, the presented modeling framework first executes the program on a cluster using limited amount of sample input data and collect performance metrics such as run time during the simulated run. 

\noindent
Next, to predict the execution time of the actual run based on the extracted performance metric from simulated run, we first calculate the number of tasks that will be executed in the actual job as follows: $ N = InputSize / BlockSize $, where $InputSize$ is the size of the input data, and $Blocksize$ is the size of one data block in HDFS. 
The tasks within a stage are scheduled to run batch by batch, and the number of tasks in each batch $P$ is computed as shown in equation (\ref{paralltask}). In one batch of tasks, while the tasks may start simultaneously, they may not finish at the same time due to various factors such as data skew problem, and differences in computing capability of different worker nodes. Hence, using sampled data, we calculate the average execution time for a task for a given stage for a worker node $h$ as follows. 
\begin{IEEEeqnarray}{rCl}
\label{taskest}
TaskRunTime_{h,i} &{} ={}& DeserializeTime_{h,i} \nonumber \\
&&+ RunTime_{h,i} \nonumber \\
&&+ SerializationTime_{h,i} \\
\label{avgtask}
AvgTaskTime_h &{} ={}& \frac{1}{n_h}\sum_{i=1}^{n_h} TaskRunTime_{h,i}
\end{IEEEeqnarray}
Here $n_h$ is the number of tasks running in host $h$ in a particular stage of the sample job. 
Moreover, during our experiment, we observed that the average execution time of the first batch is significantly different compared to the subsequent batches within the same stage, which we capture as follows. 
\begin{IEEEeqnarray}{rCl}
\label{ratio}
Ratio_h=\frac{\frac{1}{n_h-P_h} \sum_{i= P_h + 1}^{n_h}TaskTime_{h,i}}{\frac{1}{P_h} \sum_{j=1}^{P_h} TaskTime_{h,j}}
\end{IEEEeqnarray}
Here $n_h$ is the number of tasks running in host $h$, and $P_h$ is the number of tasks in the first batch. As tasks execute on different hosts in parallel, to predict the execution time for a particular stage during actual execution, stage $Startup$ time and $Cleanup$ time are viewed as constants which are extracted from simulation logs, and stage execution time is estimated as follows: 
\begin{IEEEeqnarray}{rCl}
\label{stageest}
EstStageTime&{} ={}&Startup + \max_{c=1}^{P} \sum_{i=1}^{K_c} AvgTaskTime_{c,i} \nonumber \\
&&+ Cleanup \\
\label{stagetask}
EstTaskTime_{c,i}&{} ={}&\left\{\begin{IEEEeqnarraybox}[\relax][c]{l's}
AvgTaskTime_c,& $i = 1$\\
AvgLaterTaskTime_c,& $i > 1$%
\end{IEEEeqnarraybox}\right.
\end{IEEEeqnarray}
Here $P$ is the number of total CPU cores calculated in equation (\ref{paralltask}), $K_c$ is the number of sequential tasks running in CPU core $c$. $AvgTaskTime_c$ is the average time of first batch tasks in CPU core $c$ of the corresponding host, and is calculated in equation (\ref{avgtask}). $AvgLaterTaskTime_c$ is the average time of the following batches of tasks, which could be calculated as $Ratio_h \times AvgTaskTime_h$.
\noindent
While we can apply the prediction model presented in this section, which was developed in our previous paper \cite{wangperformance}, to estimate the execution time for a single job assuming no interference, we still need a way to predict the slowdown ratio when interfered with other jobs, which we address as follows.
\subsection{Modeling Interference}
As different stages of a job is expected to have different characteristics in terms of resource utilization (e.g., CPU, I/O, memory), different stages of multiple jobs running concurrently on a system is expected to result in different interference pattern, affecting the execution time differently. Based on this observation, we model the slowdown ratio due to interference among multiple jobs for each stage separately. Towards that, in our model, each stage is represented as a vector consisting of execution time, CPU usage, disk I/O rate, and network I/O rate as follows.
\begin{equation}
\label{res}
Res_i = (RunTime_i, CPU_i, DiskIO_i, NetIO_i)
\end{equation}
Here $1 \leq i \leq M$, and $M$ is the number of stages in a job.
\par \noindent 
Next, the slowdown resulting from interference with other applications for a particular stage is represented as follows.
\begin{equation}
\label{slowdownratio}
SlowdownRatio(Stage_{i,k})
= f(Res_{i,k},Res_{Other jobs})
\end{equation}
\nop{
\begin{equation}
\label{setS}
SetS = \{Stage_{k,i} \mid 1 \leq k \leq J \ , 1 \leq i \leq M \}
\end{equation}
}
\noindent
Here $1 \leq k \leq J$ , $1 \leq i \leq M$, $J$ is the number of jobs running in parallel, $M$ is the number of stages in the Apache Spark job. $Res_{Otherjobs}$ represents the resources consumed by other jobs that are running concurrently with $Stage_{i,k}$. 
Simply put, this slowdown ratio is the ratio between execution time with interference over execution time without interference for a particular stage. Hence, once we can estimate the value of the slowdown ratio and the expected execution time when there is no interference, we can estimate the execution time if there are interference with other jobs. 
%Please note that, once we collect the resource usage profile by running sample jobs, we need to estimate the execution time of original job. The difference between original job and sample job is the size of input data, which decides the number of tasks in one stage.
\noindent
As the slowdown happens primarily due to contention for bottleneck resources in the system, to better understand the underlying reasons behind the slowdown, we ran a series of experiments and collected job event logs and resource consumption data, and then extracted the resource usage profile for each stage. Job event log is generated by Apache Spark platform, and resource consumption data is collected using system monitoring tool dstat \cite{dstat}. Apache Spark log records the time line of different stages of a running job, which was used to determine the submission and completion time of different stages of a job. The resource usage for different stages of a job is represented as below: 
\begin{equation}
\label{cpu}
CPU_i 
= (CPUusr_i, CPUsys_i, CPUidle_i, CPUwait_i) 
\end{equation}
\begin{equation}
\label{diskio}
DiskIO_i = (RateofDiskRead_i, RateofDiskWrite_i)
\end{equation}
\begin{equation}
\label{netio}
NetIO_i = (RateofNetReceive_i, RateofNetSend_i)
\end{equation}
Here $1 \leq i \leq M$, and $M$ is the number of stages in a Apache Spark job.
\noindent 
As an Apache Spark job uses in-memory data processing to reduce execution time, in the first stage of a job, it reads the input data to memory, and then analyzes the in-memory data in the subsequent stages. Due to this characteristic, in the first stage, frequent I/O is expected, leading to longer I/O wait. Based on this observation, as bulk of the disk I/O happens in the first stage, in our model, we calculate the slowdown ratio for the first stage only, and assume that the slowdown ratio in cases where the first stage interferes with the following stages from another job is 1.0 (i.e., the slowdown due to interference is expected to be minimal). Please note that, while this assumption is not accurate for certain jobs and stages, the error introduced due to this assumption in prediction accuracy is not significant. 

\nop{
In our cluster, the Maximum network transaction speed is 118MB/s tested by using iperf command, and the maximum disk I/O is 266MB/s tested by using dd command. We find that the network I/O or disk I/O speed can not reach the maximum value when we run Apache Spark job in the cluster, but the cpu usage often achieves high value. From this observation, we infer that the bottleneck of Apache Spark job is often in CPU usage, which determines the execution time of the job stage. CPU usage is calculated as the sum of the user and system CPU usage. And high level of CPU usage means the high processing speed in this stage, which will result in less execution time.
}
\noindent 
As most of the time spent in the first stage is due to reading data from disk to memory, we represent the relationship between the amount of data read in the first stage (e.g., size of input data), the rate of disk read, and the execution time of the first stage as follows: 
\begin{equation}
\label{diskread}
RunTime_{Stage 1}=c \times \frac{Input Data Size}{Rate of DiskRead_{Stage 1}} \end{equation}
\noindent 
Now, if we assume that we execute the same job twice, once with reduced input data set (i.e., sample job) and once with the complete input data set (i.e., complete job), from equation~\ref{diskread}, we can have the following. Please note that the word {\textbf{Int.}} refers to {\textbf{Interference}} in the following equations. 
\begin{equation}
\label{sampleFull}
\begin{gathered}
\frac{InputDataSize_{Sample job}}{InputDataSize_{Complete job}} = \\
\frac{Rate of Disk Read_{Sample job, Stage 1}}{RateofDiskRead_{Complete job, Stage 1}} \times \\
\frac{RunTime_{Sample Job, Stage 1}}{RunTime_{Complete job without Int., Stage 1}}
\end{gathered}
\end{equation}
Based on equation~\ref{sampleFull}, we can have the following equation for predicting the rate of disk read for a complete job. 
\begin{eqnarray}
\label{fullDiskIORead}
\begin{gathered}
Predicted Rate of Disk Read_{Complete Job without Int., Stage1} \nonumber = \\
Rate of Disk Read_{Sample Job, Stage 1} \times \\
\frac{RunTime_{Sample Job, Stage 1}}{RunTime_{Complete Job without Int., Stage 1}} \times \frac{Input Size_{Complete Job}}{Input Size_{Sample Job}}
\end{gathered}
\end{eqnarray}
\noindent
Please note that, in the above equation, we can estimate the value of $RunTime_{Complete Job without Int., Stage 1}$ using the model described in Section~\ref{oldmodel} from our earlier work~\cite{wangperformance}. Once we predict the rate of disk read for a complete job with no interference, next, we need to model the relation between the rate of disk read and the slowdown ratio when there is interference. For that, first, we run a simulation program (written by us as described in Section~\ref{evaluation}) to collect the runtime information with and without interference and calculate the parameter $\beta_{n}$ as follows.
\begin{equation}
\label{beta}
\begin{gathered}
\beta_{n} = \frac{1}{Rate of Disk Read_{Simulation Run without Int., Stage 1}} \times \\
(\frac{RunTime_{Simulation Run with Int. for n jobs, Stage 1}}{RunTime_{Simulation Run without Int., Stage 1}} - \\
\floor*{\frac{RunTime_{Simulation Run with Int. for n jobs, Stage 1}}{RunTime_{Simulation run without Int., Stage 1}}})
\end{gathered}
\end{equation}
\noindent
In this paper, we assume that there can be at most 4 concurrent jobs in a system, and varied $n$ between 2 to 4 to calculate $\beta_{2}$, $\beta_{3}$, and $\beta_{4}$. Please note that running the simulation job and calculating $\beta_{n}$ takes only few minutes and need to be done only once, making this approach quite scalable. Next, we use $\beta_{n}$ to estimate the slowdown ratio when there are $n$ concurrent jobs in the system as follows.
\begin{equation}
\label{slowdisk}
\begin{gathered}
SlowdownRatio(Stage_{(1,k)})=\\
\frac{RunTime_{Complete Job with Int., Stage 1}}{RunTime_{Complete Job without Int., Stage 1}} = \\
\beta_{n} \times PredictedRateofDiskRead_{Complete Job without Int., Stage 1} +\\ \floor*{\frac{Run Time_{Simulation run with Int., Stage 1}}{Run Time_{Simulation Run without Int., Stage 1}}}
\end{gathered}
\end{equation}
\subsection{The Cascading Effect}
Given the above formulation, if we assume that all the jobs are of same type and start at the same time, modeling interference is straightforward as they all have the same execution behavior in each stage. However, for interference among different types of jobs possibly starting at different times, this is a bit more complicated due to possible cascading effect. For example, the slowdown of stage 1 of job $A$ may push this stage to interfere with stage 2 of job $B$. Hence, a dynamic interference estimation algorithm is designed to solve this problem. The main idea behind the algorithm is as follows. First, the algorithm uses the execution time line of each job as input, and calculates the slowdown ratio for each stage of different jobs within the same time slot, and generates the execution time line of each job under interference condition. Based on that, the algorithm identifies the job that will finish its first stage the earliest, removes that job from the list, and recalculates the effect of interference for the remaining jobs for the remainder of the execution time. The algorithm applies this repeatedly until the list becomes empty. This dynamic interference estimation algorithm is described in Algorithm~\ref{algo}.

\begin{algorithm}[h]
\SetKwProg{Fn}{Function}{}{end}
\SetKwInput{KwIn}{Input}
\SetKwInput{KwOut}{Output}
\SetAlgoLined
\KwIn{List $JobProfiles$ listing Execution Information without Interference}
\KwOut{List $JobTime$ listing Execution Time with Interference}
\Fn {PredictJobExecution}{
Initialize List $Phases$, List $JobTime$\;
\For {all $job$ $\in$ $JobProfiles$ }{
$Phases$.add($job$.getStage(0)); //first stage\
}
\While{$Phases$.size $>$ 0}{ 
Initialize MinTime $\leftarrow$ MaxValue\;
\For {all $phase$ $\in$ $Phases$}{
r $\leftarrow$ $phase$.calculateSlowdownRatio($Phases$)\;
phaseTime $\leftarrow$ $phase$.getStageTime() $\times$ r\;
$phase$.setPhaseTime(phaseTime)\;
$phase$.setSlowdownRatio(r)\;
\If{phaseTime $<$ MinTime}{
MinTime $\leftarrow$ phaseTime\;
}
} 
\For {all $phase$ $\in$ $Phases$}{
\eIf{phase.getPhaseTime $=$ MinTime}{
StageTimeInterfere $\leftarrow$ MinTime $+$ $phase$.getPartialTime()\;
$JobTimes$.add($phase$ ,StageTimeInterfere)\;
$Phases$.remove($phase$)\;
\If{$JobProfiles$.hasNextStage($phase$)}{
nextStage $\leftarrow$ $JobProfiles$.nextStage($phase$)\;
$Phases$.add(nextStage)\; 
} 
}
{$phase$.setStageTime($phase$.getStageTime() $-$ $\frac{MinTime}{phase.getSlowdownRatio()}$)\;
$phase$.setPartialTime($phase$.getPartialTime $+$ MinTime)\;
}
}
}
}
\caption{Interference Estimation Algorithm}
\label{algo}
\end{algorithm}
\nop{
\par 1) Initialize an empty list $timelines$ to store the interfered time line for each job.
\par 2) Initialize a list $phases$ to store the first stage of each jobs, the size of list $phases$ is the number of jobs. 
\par 3) While list $phases$ is not empty, calculate the slowdown ratio, and compute the interfered execution time for each stage of jobs.
\par \quad a) For each $phase$ in list $phases$, find out the shortest execution time $mintime$ under interference.
\par \qquad i. Calculate $SlowdownRatio_p$ for $phase$ using equation (\ref{beta}).
\par \qquad ii. Compute the interfered execution time $time_p = phasetime \times SlowdownRatio_p$.
\par \qquad iii. If $time_p < mintime$, set $mintime=time_p$.
\par \quad b) For each $phase$ in list $phases$, update the execution information.
\par \qquad i. If phase interfered time $time_p$ equals $mintime$, add $mintime$ to list $timelines$ for corresponding job, remove current $phase$ in list $phases$ and add following stage of the same job.
\par \qquad ii. Else update $phase$ execution time $phasetime_{part} = phasetime - \frac{mintime}{SlowdownRatio_p}$.
\par 4) Find out the longest execution time $Exetime$ in list $timelines$, which is the time needed to complete all the jobs under interference. Return $Exetime$.
}
\nop{
\subsection*{C. Execution Time Prediction}
The resources consumption information and job execution time line is obtained from the sample job. The difference between sample job and original job is the size of the input data, which determines the number of tasks in one stage. For one stage of a Apache Spark job, there are $Q$ tasks in total,where $Q$ can be calculated as the number of blocks for input data. Every task in the same stage will execute the same programs, and will have the same resource consumption pattern.
\begin{equation}
Stage_i = \{Task_{i,j} \mid 1 \leq j \leq Q \}
\end{equation}
\begin{equation}
Q = \frac{InputData}{BlockSize}
\end{equation}
Based on this feature, we can estimate the execution time for jobs interfered with each other through analyzing the execution logs and resources consumption information of sample job with smaller input data size.
This prediction can be finished in three steps:
\par \noindent Step 1. Collect execution logs and resource usage profile through executing sample job.
\par \noindent Step 2. Predict the execution time and resource usage for full job.
\par \noindent Step 3. Estimate the interference among jobs and predict the execution time for jobs interfered with other jobs.
}
\nop{
Figure \ref{dstatsys} displays the resources consumption information of current system every one second.
\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{figures/dstatsys.png}
\caption{Resource usage information monitored by dstat}
\label{dstatsys}
\end{figure}
}

