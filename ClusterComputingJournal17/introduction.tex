\section{Introduction}
\label{intro}


With significant advancement in wired and wireless sensor technologies and wide adoption of Internet connectivity, researchers are exploring increasingly diverse, complex, and extensible dynamic data driven application systems (DDDAS) such as smart cities~\cite{iot}, smart grid monitoring~\cite{iot}, infrastructure and asset management~\cite{iot}, and environmental applications such as target tracking~\cite{m4,m6}, volcanic ash propagation and hazard analysis~\cite{m2,m3,m5}, just to name a few. As the scale of the applications and the volume of data that needs to be stored and processed continue to grow, service providers are increasingly adopting cloud-based solutions (e.g., Apache Hadoop~\cite{hadoop}, Apache Spark~\cite{kewencloud}) to provide reliable and scalable service while maximizing the resource utilization and minimizing the operating cost. 
%, which are often shipped with hundreds of configuration settings~\cite{Yin:2011:ESC:2043556.2043572, survey}.


\noindent
Among different cloud computing platforms, Apache Spark~\cite{spark} is one of the recently popularized open-source platforms that is currently used by over 500 organizations, including companies such as Amazon, eBay and Baidu\footnote{http://spark.apache.org/faq.html}. Apache Spark leverages the concept of resilient distributed datasets (RDDs)~\cite{rdd} and in-memory computation to enable fast processing of large volume of data, making it suitable for large-scale data analytic applications. However, while performance prediction in such systems is important to optimize resource allocation~\cite{khan2015hadoop}~\cite{cheng2015resource}~\cite{delimitrou2014quasar}, it is nontrivial for Apache Spark jobs for several reasons as follows. First, the execution time of a particular job on Apache Spark platform can vary significantly depending on the input data type and size, design and implementation of the algorithm, and computing capability (e.g., number of nodes, CPU speed, memory size), making it difficult to predict job performance. Second and finally, with advancement in hardware technology, virtualization technique is increasingly being used to share resources among applications~\cite{hybridmr}. However, while virtualization isolates multiple applications running on separate virtual machines, the interference among these applications still affects the execution performance. Due to the aforementioned factors, modeling performance of multiple Apache Spark jobs running in a virtualized environment concurrently is extremely challenging. While our own prior effort looked into the problem of performance prediction for a single job running on Apache Spark platform~\cite{wangperformance}, that approach does not address the challenge of performance modeling for multiple jobs running in parallel on the same cluster.



\noindent
To address this void, in this paper, we focus on modeling interference among multiple Apache Spark jobs, and predict the execution time of a job when interfered with other jobs.
In contrast to hard to interpret machine learning approaches that are often used to predict system performance leveraging past system execution data, we apply analytical approach that can provide a better understanding regarding the observed behavior (e.g., execution slowdown), exposing the underlying interactions among multiple jobs~\cite{ousterhout2015making}~\cite{noorshams2014automated}~\cite{zhu2012performance}~\cite{lai2014io}. Specifically, we use a simulation job (an Apache Spark job implemented by us) to predict the slowdown ratio while running multiple jobs concurrently, and use the slowdown ratio to predict the execution time. As Apache spark jobs follow a multi-stage execution model (more details are discussed in Section~\ref{overview}) and different stages have different characteristics (e.g., I/O intensive vs. CPU intensive), our framework develops interference models for each stage, and predicts execution time for each stage separately. Finally, as concurrent Apache Spark jobs can heavily interfere, we design and implement a scheduler that automatically schedules and executes submitted Spark jobs leveraging the performance prediction framework, minimizing interference and reducing job execution time significantly. 



\noindent
We evaluated our framework with four real-world applications, namely, Page Rank, K-means clustering algorithm, Logistic regression, and Word Count application. We varied the number of concurrent jobs up to 4 and predicted execution time for individual stages. While the prediction accuracy for individual stages varied, it ranged between 86\% to 99\% when the number of concurrent jobs was four and all started simultaneously, and ranged between 71\% to 99\% when the number of concurrent jobs was four and started at different times. Furthermore, the scheduling algorithm reduced the average execution time of individual jobs and the total execution time (i.e., completion time of the last job minus the start time of the first job) significantly, and ranged between 47\% to 26\% for individual jobs and 2\% to 13\% for total execution time respectively.

\noindent
The rest of the paper is organized as follows. Section~\ref{related} describes prior research that is related to our work. Section~\ref{overview} presents the models that are used to predict job performance and the interference aware job scheduling algorithm. Section~\ref{evaluation} presents the experimental results. Limitations of our current work and future directions are discussed in Section~\ref{discussion}. Finally, Section~\ref{conclusion} concludes the paper.



